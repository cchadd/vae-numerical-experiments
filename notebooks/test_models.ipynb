{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from vae.models.vae import VAE\n",
    "from vae.trainers.trainer import ModelTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "bs= 128\n",
    "\n",
    "def random_binarize(img):\n",
    "    return (torch.rand_like(img) < img).type(torch.float)\n",
    "\n",
    "transforms_stack = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(random_binarize),\n",
    "])\n",
    "\n",
    "train = datasets.MNIST(root='../data/',\n",
    "                       train=True,\n",
    "                       transform=transforms_stack,\n",
    "                       download=False)\n",
    "\n",
    "test = datasets.MNIST(root='../data/',\n",
    "                    train=False,\n",
    "                    transform=transforms_stack,\n",
    "                    download=False) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 46232.957031\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 46405.281250\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 46315.304688\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 46420.500000\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 46176.585938\n",
      "====> Epoch: 0 Average loss: 46285.9980 \tLikelihood: -43977.413417\n",
      "====> Test set loss: 46242.9478\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 46376.273438\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 46497.265625\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 46200.656250\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 46181.710938\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 46597.730469\n",
      "====> Epoch: 1 Average loss: 46287.1572 \tLikelihood: -43972.126758\n",
      "====> Test set loss: 46244.9335\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 46100.242188\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 46003.234375\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 46293.414062\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 46110.382812\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 46154.156250\n",
      "====> Epoch: 2 Average loss: 46275.7729 \tLikelihood: -43973.989175\n",
      "====> Test set loss: 46237.5553\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 46428.875000\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 46332.644531\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 46127.757812\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 46149.585938\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 46223.390625\n",
      "====> Epoch: 3 Average loss: 46288.3028 \tLikelihood: -43983.644617\n",
      "====> Test set loss: 46256.0462\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 46388.500000\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 46406.687500\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 46316.250000\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 46356.531250\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 46353.925781\n",
      "====> Epoch: 4 Average loss: 46288.4272 \tLikelihood: -43971.992067\n",
      "====> Test set loss: 46239.8861\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 46263.335938\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 46434.468750\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 46333.394531\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 46373.125000\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 46286.101562\n",
      "====> Epoch: 5 Average loss: 46281.3273 \tLikelihood: -43970.844300\n",
      "====> Test set loss: 46263.8083\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 46375.144531\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 46151.605469\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 46401.289062\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 46300.796875\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 46363.312500\n",
      "====> Epoch: 6 Average loss: 46291.5183 \tLikelihood: -43972.655517\n",
      "====> Test set loss: 46239.9764\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 46346.601562\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 46291.656250\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 46264.027344\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 46324.781250\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 46420.011719\n",
      "====> Epoch: 7 Average loss: 46284.2605 \tLikelihood: -43969.328267\n",
      "====> Test set loss: 46254.8397\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 46441.257812\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 46600.757812\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 46309.015625\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 46291.835938\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 46486.890625\n",
      "====> Epoch: 8 Average loss: 46283.3605 \tLikelihood: -43974.083075\n",
      "====> Test set loss: 46260.3302\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 46425.335938\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 46461.582031\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 46325.539062\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 46225.703125\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 46458.687500\n",
      "====> Epoch: 9 Average loss: 46288.4181 \tLikelihood: -43973.634992\n",
      "====> Test set loss: 46248.7115\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 46254.550781\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 46532.382812\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 46337.320312\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 46037.539062\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 46579.773438\n",
      "====> Epoch: 10 Average loss: 46287.0910 \tLikelihood: -43975.246367\n",
      "====> Test set loss: 46250.2826\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 46006.929688\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 46104.804688\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 46417.285156\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 46178.351562\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 46217.531250\n",
      "====> Epoch: 11 Average loss: 46293.2287 \tLikelihood: -43975.574992\n",
      "====> Test set loss: 46262.0265\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 46354.125000\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 46366.289062\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 46457.625000\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 46159.125000\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 46160.757812\n",
      "====> Epoch: 12 Average loss: 46291.0298 \tLikelihood: -43977.510258\n",
      "====> Test set loss: 46262.3993\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 46528.250000\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 46432.316406\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 46215.011719\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 46244.882812\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 46102.683594\n",
      "====> Epoch: 13 Average loss: 46279.5843 \tLikelihood: -43973.246792\n",
      "====> Test set loss: 46232.9122\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 45859.898438\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 46282.882812\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 46367.207031\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 46320.953125\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 46368.527344\n",
      "====> Epoch: 14 Average loss: 46279.9904 \tLikelihood: -43979.368508\n",
      "====> Test set loss: 46232.9758\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_loader.dataset.data.shape[0]\n",
    "\n",
    "trainer = ModelTrainer(vae, train_loader, test_loader, n_epochs=30)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.75"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6981c41bb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(64, 2).to(device)\n",
    "    sample = vae.decode(z)\n",
    "    sample = torch.reshape(sample, (64, 28, 28))\n",
    "plt.matshow(sample.cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
